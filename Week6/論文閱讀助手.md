# è«–æ–‡é–±è®€åŠ©æ‰‹ - Paper Reading Assistant

*This notebook was created for Google Colab*

*Language: python*

---

## å°ˆæ¡ˆç°¡ä»‹

é€™æ˜¯ä¸€å€‹åŸºæ–¼ OpenAI GPT-5 Response API çš„è«–æ–‡é–±è®€åŠ©æ‰‹ï¼Œå¹«åŠ©å­¸ç”Ÿæ›´å¥½åœ°ç†è§£å­¸è¡“è«–æ–‡ã€‚

**æ ¸å¿ƒç‰¹è‰²**ï¼š
- ğŸ“„ æ”¯æ´ PDF ä¸Šå‚³ï¼Œå®Œæ•´è§£æè«–æ–‡å…§å®¹
- ğŸ’¬ å¤šè¼ªå°è©±ï¼Œå¯ä»¥æŒçºŒæå•
- ğŸ§  è²»æ›¼å­¸ç¿’æ³•ï¼šç”¨ç°¡å–®èªè¨€è§£é‡‹è¤‡é›œæ¦‚å¿µ
- ğŸ¯ è˜‡æ ¼æ‹‰åº•å¼æå•ï¼šå¼•å°æ·±åº¦æ€è€ƒ
- ğŸ”„ å¯æ¸…é™¤å°è©±ï¼Œé‡æ–°é–‹å§‹

---

## 1. å®‰è£å¿…è¦å¥—ä»¶

```python
!pip install openai gradio pypdf2
```

---

## 2. API Key è¨­å®š

è«‹åœ¨ Colab å·¦å´çš„ ğŸ”‘ Secrets ä¸­è¨­å®šæ‚¨çš„ OpenAI API Keyï¼Œåç¨±ç‚º `OpenAI`ã€‚

```python
from google.colab import userdata
import os

api_key = userdata.get('OpenAI')
os.environ['OPENAI_API_KEY'] = api_key
```

---

## 3. åŒ¯å…¥å¿…è¦å¥—ä»¶

```python
from openai import OpenAI
import gradio as gr
import PyPDF2
from dataclasses import dataclass
from typing import List, Dict, Optional, Any
```

---

## 4. åˆå§‹åŒ– OpenAI Client

```python
client = OpenAI()
MODEL_NAME = "gpt-5"
```

---

## 5. PDF æ–‡å­—æå–å‡½æ•¸

```python
def extract_pdf_text(pdf_path: str) -> str:
    """
    å¾ä¸Šå‚³çš„ PDF æª”æ¡ˆä¸­æå–æ–‡å­—å…§å®¹

    é€™å€‹å‡½æ•¸æœƒï¼š
    1. é€é è®€å– PDF å…§å®¹
    2. éæ¿¾æ‰ç©ºç™½é é¢
    3. æ¨™è¨˜é ç¢¼æ–¹ä¾¿å®šä½
    4. é™åˆ¶æœ€å¤§é•·åº¦é¿å…è¶…é Token é™åˆ¶

    Args:
        pdf_path: PDF æª”æ¡ˆè·¯å¾‘

    Returns:
        str: æå–çš„æ–‡å­—å…§å®¹

    Raises:
        ValueError: ç•¶ PDF ç„¡æ³•è®€å–æˆ–å…§å®¹ç‚ºç©ºæ™‚
    """
    if not pdf_path:
        raise ValueError("æœªæä¾› PDF æª”æ¡ˆ")

    text_segments: List[str] = []

    try:
        with open(pdf_path, "rb") as handle:
            pdf_reader = PyPDF2.PdfReader(handle)

            if not pdf_reader.pages:
                raise ValueError("PDF ä¸­æ²’æœ‰å¯ç”¨é é¢")

            # é€é æå–æ–‡å­—
            for index, page in enumerate(pdf_reader.pages, start=1):
                # æ³¨æ„ï¼špage.extract_text() å¯èƒ½å›å‚³ Noneï¼Œéœ€è¦è™•ç†
                page_text = page.extract_text() or ""

                # åªåŠ å…¥æœ‰å…§å®¹çš„é é¢
                if page_text.strip():
                    text_segments.append(f"\n--- Page {index} ---\n{page_text.strip()}")

    except Exception as exc:
        raise ValueError(f"PDF è®€å–å¤±æ•—: {exc}") from exc

    if not text_segments:
        raise ValueError("PDF ä¸­æ²’æœ‰å¯è®€å–çš„æ–‡å­—å…§å®¹")

    # åˆä½µæ‰€æœ‰é é¢
    combined = "".join(text_segments)

    # é˜²æ­¢è¶…é Token é™åˆ¶ï¼ˆç´„ 15000 å­—å…ƒï¼‰
    MAX_PDF_CHARS = 15000
    if len(combined) > MAX_PDF_CHARS:
        combined = combined[:MAX_PDF_CHARS] + "\n\n... (å…§å®¹éé•·ï¼Œå·²æˆªæ–·ã€‚è«‹åˆ†æ®µæå•ä»¥ç²å¾—å®Œæ•´è§£èªªã€‚)"

    return combined
```

---

## 6. System Prompt è¨­å®š

é€™æ˜¯è«–æ–‡é–±è®€åŠ©æ‰‹çš„ã€Œäººè¨­ã€ï¼Œå®šç¾©äº†å®ƒå¦‚ä½•å¹«åŠ©å­¸ç”Ÿç†è§£è«–æ–‡ã€‚

```python
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è«–æ–‡é–±è®€åŠ©æ‰‹ï¼Œå°ˆé–€å¹«åŠ©å­¸ç”Ÿç†è§£å­¸è¡“è«–æ–‡ã€‚

**ä½ çš„æ•™å­¸åŸå‰‡**ï¼š

1. **è²»æ›¼å­¸ç¿’æ³• (Feynman Technique)**ï¼š
   - ç”¨æœ€ç°¡å–®çš„èªè¨€è§£é‡‹è¤‡é›œæ¦‚å¿µ
   - ä½¿ç”¨é¡æ¯”å’Œæ—¥å¸¸ç”Ÿæ´»çš„ä¾‹å­
   - é¿å…éåº¦ä½¿ç”¨å°ˆæ¥­è¡“èªï¼Œå¿…è¦æ™‚è¦å…ˆè§£é‡‹

2. **è˜‡æ ¼æ‹‰åº•å¼æå• (Socratic Method)**ï¼š
   - ä¸ç›´æ¥çµ¦ç­”æ¡ˆï¼Œè€Œæ˜¯å¼•å°å­¸ç”Ÿæ€è€ƒ
   - æå‡ºå•Ÿç™¼æ€§å•é¡Œï¼Œå¹«åŠ©å­¸ç”Ÿè‡ªå·±æ‰¾åˆ°ç­”æ¡ˆ
   - é¼“å‹µæ‰¹åˆ¤æ€§æ€ç¶­

3. **çµæ§‹åŒ–åˆ†æ**ï¼š
   - å¹«åŠ©å­¸ç”Ÿç†è§£è«–æ–‡çµæ§‹ï¼šæ‘˜è¦ã€å¼•è¨€ã€æ–¹æ³•ã€çµæœã€çµè«–
   - æŒ‡å‡ºè«–æ–‡çš„æ ¸å¿ƒè²¢ç»å’Œå‰µæ–°é»
   - è§£é‡‹ç ”ç©¶æ–¹æ³•å’Œå¯¦é©—è¨­è¨ˆ

4. **å‹å–„äº’å‹•**ï¼š
   - ä»¥é¼“å‹µå’Œæ”¯æŒçš„èªæ°£å›æ‡‰
   - ç¢ºèªå­¸ç”Ÿç†è§£å¾Œå†ç¹¼çºŒ
   - å¯ä»¥ç”¨ emoji è®“å°è©±æ›´ç”Ÿå‹•

**ç•¶å­¸ç”Ÿä¸Šå‚³è«–æ–‡å¾Œ**ï¼š
- ç­‰å¾…å­¸ç”Ÿæå•ï¼Œä¸è¦ä¸»å‹•æ‘˜è¦
- æ ¹æ“šå­¸ç”Ÿçš„å•é¡Œï¼Œå¾è«–æ–‡ä¸­æ‰¾åˆ°ç›¸é—œå…§å®¹å›ç­”
- ç¢ºä¿å›ç­”æº–ç¢ºä¸”åŸºæ–¼è«–æ–‡å…§å®¹

**è¨˜ä½**ï¼šä½ çš„ç›®æ¨™æ˜¯å¹«åŠ©å­¸ç”Ÿã€Œå­¸æœƒå¦‚ä½•è®€è«–æ–‡ã€ï¼Œè€Œä¸åªæ˜¯ã€Œè®€æ‡‚é€™ç¯‡è«–æ–‡ã€ã€‚"""

WELCOME_MESSAGE = """ğŸ‘‹ å—¨ï¼æˆ‘æ˜¯ä½ çš„**è«–æ–‡é–±è®€åŠ©æ‰‹ & AI å°è©±å¤¥ä¼´**ï¼

ğŸ“š **æˆ‘èƒ½å¹«ä½ åšä»€éº¼ï¼Ÿ**

**æ¨¡å¼ 1ï¼šè«–æ–‡é–±è®€åŠ©æ‰‹** ğŸ“„
- ä¸Šå‚³ PDF è«–æ–‡å¾Œï¼Œæˆ‘æœƒå¹«ä½ ï¼š
  - ç”¨ç°¡å–®çš„èªè¨€è§£é‡‹è«–æ–‡ä¸­çš„è¤‡é›œæ¦‚å¿µ
  - å¹«ä½ ç†è§£ç ”ç©¶æ–¹æ³•å’Œå¯¦é©—è¨­è¨ˆ
  - å¼•å°ä½ æ€è€ƒè«–æ–‡çš„æ ¸å¿ƒè²¢ç»
  - å›ç­”ä½ å°è«–æ–‡å…§å®¹çš„ä»»ä½•ç–‘å•

**æ¨¡å¼ 2ï¼šä¸€èˆ¬ AI åŠ©æ‰‹** ğŸ’¬
- ä¸ä¸Šå‚³ PDF ä¹Ÿå¯ä»¥ç›´æ¥è·Ÿæˆ‘èŠå¤©ï¼š
  - å­¸ç¿’ä»»ä½•ä¸»é¡Œ
  - è§£ç­”å•é¡Œ
  - è¨è«–æƒ³æ³•
  - å¯«ä½œå”åŠ©

ğŸš€ **å¦‚ä½•é–‹å§‹ï¼Ÿ**
- **æƒ³è®€è«–æ–‡ï¼Ÿ** é»æ“Šä¸Šæ–¹ã€Œä¸Šå‚³ PDFã€æŒ‰éˆ•
- **æƒ³èŠå¤©ï¼Ÿ** ç›´æ¥é–‹å§‹æå•å³å¯ï¼

ğŸ’¡ **æå•ç¯„ä¾‹**ï¼š
- ğŸ“– è«–æ–‡ç›¸é—œï¼šã€Œé€™ç¯‡è«–æ–‡çš„ä¸»è¦è²¢ç»æ˜¯ä»€éº¼ï¼Ÿã€
- ğŸ’¬ ä¸€èˆ¬å°è©±ï¼šã€Œè§£é‡‹ä¸€ä¸‹æ©Ÿå™¨å­¸ç¿’çš„åŸºæœ¬æ¦‚å¿µã€

æº–å‚™å¥½äº†å—ï¼Ÿé–‹å§‹ä½ çš„æ¢ç´¢ä¹‹æ—…å§ï¼ ğŸš€âœ¨"""

PDF_CONTEXT_TEMPLATE = (
    "ä»¥ä¸‹æ˜¯ä½¿ç”¨è€…æä¾›çš„è«–æ–‡å…§å®¹ (æª”å: {filename}, ç‰ˆæœ¬: {version})ï¼Œå›ç­”æ™‚å‹™å¿…å¼•ç”¨æ­¤å…§å®¹ï¼š\n"
    "{content}"
)
```

---

## 7. ç‹€æ…‹ç®¡ç† - ä½¿ç”¨ Dataclass

ä½¿ç”¨çµæ§‹åŒ–çš„æ–¹å¼ç®¡ç† PDF å’Œå°è©±ç‹€æ…‹ï¼Œæ¯”å–®ç´”çš„å…¨åŸŸè®Šæ•¸æ›´æ¸…æ™°ä¸”æ˜“æ–¼ç¶­è­·ã€‚

```python
@dataclass
class PDFState:
    """
    ç®¡ç† PDF ç‹€æ…‹çš„è³‡æ–™é¡åˆ¥

    Attributes:
        filename: PDF æª”å
        content: æå–çš„æ–‡å­—å…§å®¹
        version: PDF ç‰ˆæœ¬è™Ÿï¼ˆæ¯æ¬¡ä¸Šå‚³æ–° PDF æœƒéå¢ï¼‰
    """
    filename: Optional[str] = None
    content: Optional[str] = None
    version: int = 0

    def context_message(self) -> Optional[Dict[str, str]]:
        """
        ç”¢ç”ŸåŒ…å« PDF å…§å®¹çš„è¨Šæ¯ç‰©ä»¶

        é€™å€‹è¨Šæ¯æœƒåœ¨æ¯æ¬¡ API å‘¼å«æ™‚æ’å…¥ï¼Œç¢ºä¿æ¨¡å‹çŸ¥é“ç•¶å‰çš„ PDF å…§å®¹ã€‚
        ä½¿ç”¨ç‰ˆæœ¬è™Ÿå¯ä»¥è®“æ¨¡å‹å€åˆ†ä¸åŒçš„ PDFã€‚

        Returns:
            åŒ…å« PDF å…§å®¹çš„ user è¨Šæ¯ï¼Œå¦‚æœæ²’æœ‰ PDF å‰‡å›å‚³ None
        """
        if not self.content or not self.filename:
            return None

        return {
            "role": "user",
            "content": PDF_CONTEXT_TEMPLATE.format(
                filename=self.filename,
                version=self.version,
                content=self.content,
            ),
        }


# å…¨åŸŸç‹€æ…‹è®Šæ•¸
conversation_history: List[Dict[str, str]] = []  # å„²å­˜å°è©±æ­·å²ï¼ˆuser å’Œ assistant è¨Šæ¯ï¼‰
last_response_id: Optional[str] = None  # Response API çš„ previous_response_id
pdf_state = PDFState()  # PDF ç‹€æ…‹
```

---

## 8. è¼”åŠ©å‡½æ•¸

```python
def summarise_outputs(response: Any) -> str:
    """
    å¾ Response API çš„å›æ‡‰ä¸­æå–æ–‡å­—å…§å®¹

    Response API çš„è¼¸å‡ºæ ¼å¼æ¯”è¼ƒè¤‡é›œï¼Œå¯èƒ½åŒ…å«ï¼š
    - output_text: ç›´æ¥çš„æ–‡å­—è¼¸å‡ºï¼ˆæœ€å¸¸è¦‹ï¼‰
    - output: åŒ…å«å¤šå€‹ message ç‰©ä»¶çš„é™£åˆ—ï¼ˆéœ€è¦æ‰‹å‹•è§£æï¼‰

    é€™å€‹å‡½æ•¸æœƒå˜—è©¦å…©ç¨®æ–¹å¼ï¼Œç¢ºä¿èƒ½å–å¾—å…§å®¹ã€‚

    Args:
        response: OpenAI Response API çš„å›æ‡‰ç‰©ä»¶

    Returns:
        str: æå–çš„æ–‡å­—å…§å®¹
    """
    # å„ªå…ˆä½¿ç”¨ output_text
    if getattr(response, "output_text", None):
        return response.output_text

    # å¦‚æœæ²’æœ‰ output_textï¼Œæ‰‹å‹•è§£æ output é™£åˆ—
    collected: List[str] = []
    for item in getattr(response, "output", []) or []:
        if item.get("type") != "message":
            continue
        for chunk in item.get("content", []):
            if chunk.get("type") == "output_text" and chunk.get("text"):
                collected.append(chunk["text"])

    return "".join(collected).strip()


def ensure_history(history: Optional[List[List[str]]]) -> List[List[str]]:
    """
    ç¢ºä¿ Gradio history æ˜¯æœ‰æ•ˆçš„åˆ—è¡¨

    Gradio åœ¨ç¬¬ä¸€æ¬¡å‘¼å«æ™‚å¯èƒ½å‚³å…¥ Noneï¼Œé€™æœƒå°è‡´éŒ¯èª¤ã€‚
    é€™å€‹å‡½æ•¸ç¢ºä¿æˆ‘å€‘ç¸½æ˜¯æœ‰ä¸€å€‹æœ‰æ•ˆçš„åˆ—è¡¨å¯ä»¥æ“ä½œã€‚

    Args:
        history: Gradio å‚³å…¥çš„å°è©±æ­·å²ï¼ˆå¯èƒ½æ˜¯ Noneï¼‰

    Returns:
        æœ‰æ•ˆçš„å°è©±æ­·å²åˆ—è¡¨
    """
    return list(history) if history else []
```

---

## 9. æ ¸å¿ƒå°è©±å‡½æ•¸

```python
def chat_with_paper(message: str, history: Optional[List[List[str]]]):
    """
    è™•ç†ä½¿ç”¨è€…è¨Šæ¯ä¸¦ç”¢ç”Ÿå›æ‡‰

    **é‡è¦æ”¹é€²**ï¼ˆç›¸è¼ƒæ–¼åŸæœ¬çš„å¯¦ä½œï¼‰ï¼š
    1. âœ… æ­£ç¢ºå„²å­˜ user å’Œ assistant è¨Šæ¯åˆ° conversation_history
    2. âœ… æ¯æ¬¡å‘¼å«éƒ½é‡æ–°æ³¨å…¥ PDF å…§å®¹ï¼ˆæ”¯æ´é‡æ–°ä¸Šå‚³ï¼‰
    3. âœ… ä½¿ç”¨ previous_response_id ç¶­è­· Response API çš„ç‹€æ…‹
    4. âœ… è™•ç† history=None çš„é‚Šç•Œæƒ…æ³
    5. âœ… è™•ç†ç©ºç™½è¼¸å‡ºçš„æƒ…æ³

    æ”¯æ´å…©ç¨®æ¨¡å¼ï¼š
    1. æœ‰ PDFï¼šè«–æ–‡é–±è®€åŠ©æ‰‹æ¨¡å¼
    2. ç„¡ PDFï¼šä¸€èˆ¬ AI åŠ©æ‰‹æ¨¡å¼

    Args:
        message: ä½¿ç”¨è€…ç•¶å‰è¼¸å…¥
        history: Gradio èŠå¤©æ­·å² [[user_msg, bot_msg], ...]

    Returns:
        list: æ›´æ–°å¾Œçš„ Gradio æ­·å²è¨˜éŒ„ï¼ˆå¿…é ˆæ˜¯ list of lists æ ¼å¼ï¼‰
    """
    global conversation_history, last_response_id

    # ç¢ºä¿ history æ˜¯æœ‰æ•ˆçš„åˆ—è¡¨
    history = ensure_history(history)

    # éæ¿¾ç©ºç™½è¨Šæ¯
    user_message = (message or "").strip()
    if not user_message:
        return history

    # === æ­¥é©Ÿ 1: å»ºæ§‹è¨Šæ¯é™£åˆ— ===
    messages: List[Dict[str, str]] = [
        {"role": "developer", "content": SYSTEM_PROMPT}
    ]

    # === æ­¥é©Ÿ 2: å¦‚æœæœ‰ PDFï¼Œæ³¨å…¥ PDF å…§å®¹ ===
    # æ³¨æ„ï¼šæ¯æ¬¡éƒ½é‡æ–°æ³¨å…¥ï¼Œé€™æ¨£é‡æ–°ä¸Šå‚³ PDF æ™‚æ¨¡å‹æœƒçŸ¥é“
    pdf_context = pdf_state.context_message()
    if pdf_context:
        messages.append(pdf_context)

    # === æ­¥é©Ÿ 3: åŠ å…¥å°è©±æ­·å² ===
    # é€™è£¡åŒ…å«ä¹‹å‰æ‰€æœ‰çš„ user å’Œ assistant è¨Šæ¯
    messages.extend(conversation_history)

    # === æ­¥é©Ÿ 4: åŠ å…¥ç•¶å‰ä½¿ç”¨è€…è¨Šæ¯ ===
    messages.append({"role": "user", "content": user_message})

    # === æ­¥é©Ÿ 5: æº–å‚™ API è«‹æ±‚ ===
    request_payload = {
        "model": MODEL_NAME,
        "input": messages,
        "reasoning": {"effort": "medium"},
        "text": {"verbosity": "medium"}
    }

    # å¦‚æœæœ‰ä¸Šä¸€æ¬¡çš„ response_idï¼ŒåŠ å…¥ä»¥ç¶­æŒæ¨ç†é€£çºŒæ€§
    if last_response_id:
        request_payload["previous_response_id"] = last_response_id

    try:
        # === æ­¥é©Ÿ 6: å‘¼å« OpenAI Response API ===
        response = client.responses.create(**request_payload)

        # === æ­¥é©Ÿ 7: æå–å›æ‡‰æ–‡å­— ===
        assistant_reply = summarise_outputs(response)

        # å¦‚æœæ²’æœ‰æ–‡å­—è¼¸å‡ºï¼ˆç½•è¦‹ä½†å¯èƒ½ç™¼ç”Ÿï¼‰ï¼Œæä¾›å‹å–„çš„éŒ¯èª¤è¨Šæ¯
        if not assistant_reply:
            assistant_reply = "âš ï¸ æ¨¡å‹æœªå›å‚³æ–‡å­—ï¼Œå¯å†è©¦ä¸€æ¬¡æˆ–èª¿æ•´å•é¡Œã€‚"

        # === æ­¥é©Ÿ 8: æ›´æ–°å°è©±æ­·å²ï¼ˆé‡è¦ï¼ï¼‰===
        # å„²å­˜ user å’Œ assistant è¨Šæ¯ï¼Œé€™æ¨£ä¸‹æ¬¡å‘¼å«æ™‚æ¨¡å‹æ‰çŸ¥é“ä¹‹å‰çš„å°è©±
        conversation_history.append({"role": "user", "content": user_message})
        conversation_history.append({"role": "assistant", "content": assistant_reply})

        # === æ­¥é©Ÿ 9: å„²å­˜ response_id ===
        last_response_id = getattr(response, "id", None)

        # === æ­¥é©Ÿ 10: æ›´æ–° Gradio é¡¯ç¤ºçš„æ­·å² ===
        history.append([user_message, assistant_reply])
        return history

    except Exception as exc:
        # éŒ¯èª¤è™•ç†ï¼šåŒæ¨£å›å‚³ Gradio æ ¼å¼
        error_message = f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{exc}\n\nè«‹æª¢æŸ¥ç¶²è·¯é€£ç·šèˆ‡ API è¨­å®šå¾Œå†è©¦ä¸€æ¬¡ã€‚"
        history.append([user_message, error_message])
        return history


def upload_pdf(pdf_file: Optional[str]):
    """
    è™•ç† PDF ä¸Šå‚³

    **é‡è¦æ”¹é€²**ï¼š
    1. âœ… æ›´æ–° pdf_state çš„ç‰ˆæœ¬è™Ÿï¼Œè®“æ¨¡å‹çŸ¥é“æ˜¯æ–°çš„ PDF
    2. âœ… ä¿ç•™ conversation_historyï¼ˆå°è©±æ­·å²ä¸æœƒå› ç‚ºä¸Šå‚³ PDF è€Œæ¶ˆå¤±ï¼‰
    3. âœ… ä¸‹æ¬¡æå•æ™‚æœƒè‡ªå‹•æ³¨å…¥æ–°çš„ PDF å…§å®¹

    Args:
        pdf_file: Gradio ä¸Šå‚³çš„æª”æ¡ˆè·¯å¾‘

    Returns:
        str: ä¸Šå‚³ç‹€æ…‹è¨Šæ¯
    """
    global pdf_state

    if pdf_file is None:
        return "âŒ è«‹é¸æ“‡ PDF æª”æ¡ˆ"

    try:
        # æå– PDF æ–‡å­—
        content = extract_pdf_text(pdf_file)
    except ValueError as exc:
        # å¦‚æœæå–å¤±æ•—ï¼Œé‡ç½® PDF ç‹€æ…‹
        pdf_state = PDFState()
        return f"âŒ {exc}"

    # æ›´æ–° PDF ç‹€æ…‹ï¼ˆç‰ˆæœ¬è™Ÿéå¢ï¼‰
    pdf_state = PDFState(
        filename=os.path.basename(pdf_file),
        content=content,
        version=pdf_state.version + 1,
    )

    # è¨ˆç®—çµ±è¨ˆè³‡è¨Š
    page_count = content.count("--- Page") or "?"
    char_count = len(content)

    # ç”¢ç”Ÿå‹å–„çš„æˆåŠŸè¨Šæ¯
    note = (
        "âœ… PDF ä¸Šå‚³æˆåŠŸï¼\n\n"
        f"ğŸ“„ æª”åï¼š{pdf_state.filename}\n"
        f"ğŸ“„ ç‰ˆæœ¬ï¼š{pdf_state.version}\n"
        f"ğŸ“„ é é¢æ•¸ï¼šç´„ {page_count}\n"
        f"ğŸ”¤ æ–‡å­—é•·åº¦ï¼šç´„ {char_count:,} å­—å…ƒ\n\n"
        "ğŸ’¬ ä½ å¯ä»¥ç›´æ¥æå•ï¼Œæˆ‘æœƒä¾æ“šæœ€æ–°çš„ PDF å›ç­”ã€‚"
    )

    return note


def clear_conversation():
    """
    æ¸…é™¤å°è©±æ­·å²ï¼Œé‡æ–°é–‹å§‹

    æ³¨æ„ï¼šåªæ¸…é™¤å°è©±æ­·å²ï¼ŒPDF è¨­å®šä¿æŒä¸è®Š

    Returns:
        tuple: (æ¸…ç©ºçš„èŠå¤©æ­·å², ç‹€æ…‹è¨Šæ¯)
    """
    global conversation_history, last_response_id

    conversation_history = []
    last_response_id = None

    return [], "ğŸ”„ å°è©±å·²æ¸…é™¤ï¼PDF è¨­å®šä¿æŒä¸è®Šã€‚"
```

---

## 10. Gradio ä»‹é¢è¨­è¨ˆ

```python
# å»ºç«‹ Gradio ä»‹é¢
with gr.Blocks(title="è«–æ–‡é–±è®€åŠ©æ‰‹", theme=gr.themes.Soft()) as demo:

    gr.Markdown("# ğŸ“š è«–æ–‡é–±è®€åŠ©æ‰‹ - Paper Reading Assistant")
    gr.Markdown("åŸºæ–¼ OpenAI GPT-5 Response APIï¼Œçµåˆè²»æ›¼å­¸ç¿’æ³•èˆ‡è˜‡æ ¼æ‹‰åº•å¼æå•")

    with gr.Row():
        with gr.Column(scale=3):
            # PDF ä¸Šå‚³å€
            pdf_upload = gr.File(
                label="ğŸ“„ ä¸Šå‚³è«–æ–‡ PDF",
                file_types=[".pdf"],
                type="filepath"
            )
            upload_status = gr.Textbox(
                label="ä¸Šå‚³ç‹€æ…‹",
                value=WELCOME_MESSAGE,
                interactive=False,
                lines=10
            )

        with gr.Column(scale=7):
            # èŠå¤©å€
            chatbot = gr.Chatbot(
                label="ğŸ’¬ å°è©±å€",
                height=500,
                show_label=True,
                type="tuples"  # æ˜ç¢ºæŒ‡å®šä½¿ç”¨ tuples æ ¼å¼
            )

            msg_input = gr.Textbox(
                label="è¼¸å…¥ä½ çš„å•é¡Œ",
                placeholder="ä¾‹å¦‚ï¼šé€™ç¯‡è«–æ–‡çš„ä¸»è¦è²¢ç»æ˜¯ä»€éº¼ï¼Ÿ",
                lines=2
            )

            with gr.Row():
                submit_btn = gr.Button("ğŸ“¤ é€å‡º", variant="primary")
                clear_btn = gr.Button("ğŸ”„ æ¸…é™¤å°è©±")

    # äº‹ä»¶ç¶å®š
    pdf_upload.change(
        fn=upload_pdf,
        inputs=pdf_upload,
        outputs=upload_status
    )

    submit_btn.click(
        fn=chat_with_paper,
        inputs=[msg_input, chatbot],
        outputs=chatbot
    ).then(
        lambda: "",  # æ¸…ç©ºè¼¸å…¥æ¡†
        outputs=msg_input
    )

    msg_input.submit(
        fn=chat_with_paper,
        inputs=[msg_input, chatbot],
        outputs=chatbot
    ).then(
        lambda: "",  # æ¸…ç©ºè¼¸å…¥æ¡†
        outputs=msg_input
    )

    clear_btn.click(
        fn=clear_conversation,
        outputs=[chatbot, upload_status]
    )

    # èªªæ˜å€
    gr.Markdown("""
    ---
    ### ğŸ’¡ ä½¿ç”¨æŠ€å·§

    - **ç¬¬ä¸€æ¬¡æå•**ï¼šå»ºè­°å…ˆå•ã€Œé€™ç¯‡è«–æ–‡åœ¨ç ”ç©¶ä»€éº¼ï¼Ÿã€äº†è§£å…¨è²Œ
    - **æ·±å…¥ç†è§£**ï¼šé‡å°ä¸æ‡‚çš„ç« ç¯€æˆ–æ¦‚å¿µæå•
    - **æ‰¹åˆ¤æ€è€ƒ**ï¼šå¯ä»¥å•ã€Œé€™å€‹æ–¹æ³•æœ‰ä»€éº¼é™åˆ¶ï¼Ÿã€
    - **æ¸…é™¤å°è©±**ï¼šæƒ³é‡æ–°é–‹å§‹æ™‚ï¼Œé»æ“Šã€Œæ¸…é™¤å°è©±ã€æŒ‰éˆ•
    - **é‡æ–°ä¸Šå‚³ PDF**ï¼šå¯ä»¥éš¨æ™‚ä¸Šå‚³æ–°çš„ PDFï¼Œå°è©±æ­·å²æœƒä¿ç•™

    ### âš™ï¸ æŠ€è¡“èªªæ˜

    - **æ¨¡å‹**ï¼šOpenAI GPT-5 (Response API)
    - **æ¨ç†ç­‰ç´š**ï¼šMedium (å¹³è¡¡é€Ÿåº¦èˆ‡å“è³ª)
    - **PDF è™•ç†**ï¼šPyPDF2 (å®Œæ•´æ–‡å­—æå–)
    - **ä»‹é¢æ¡†æ¶**ï¼šGradio 5.x

    ---
    *Made with â¤ï¸ for NCCU AI Course*
    """)
```

---

## 11. å•Ÿå‹•æ‡‰ç”¨

```python
# å•Ÿå‹• Gradio æ‡‰ç”¨
demo.launch(share=True, debug=True)
```

**å•Ÿå‹•å¾Œ**ï¼š
- Gradio æœƒç”¢ç”Ÿä¸€å€‹å…¬é–‹é€£çµï¼ˆä¾‹å¦‚ï¼š`https://xxx.gradio.live`ï¼‰
- é€™å€‹é€£çµå¯ä»¥åˆ†äº«çµ¦ä»»ä½•äººä½¿ç”¨
- é€£çµæœ‰æ•ˆæœŸï¼š72 å°æ™‚

---

## ğŸ“¸ ä½¿ç”¨ç¯„ä¾‹æˆªåœ–

*(åœ¨å¯¦éš›ä½¿ç”¨æ™‚ï¼Œè¨˜å¾—æˆªåœ–ä»¥ä¸‹ç•«é¢)*

1. **ä¸Šå‚³ PDF æˆåŠŸç•«é¢**
2. **ç¬¬ä¸€æ¬¡æå• + å›æ‡‰**
3. **å¤šè¼ªå°è©±å±•ç¤º**
4. **è²»æ›¼å­¸ç¿’æ³•è§£é‡‹ç¯„ä¾‹**
5. **è˜‡æ ¼æ‹‰åº•å¼æå•ç¯„ä¾‹**

---

## ğŸ“ å­¸ç¿’é‡é»

### Response API vs Chat Completions

é€™å€‹å°ˆæ¡ˆä½¿ç”¨äº†æœ€æ–°çš„ **OpenAI Response API**ï¼Œç›¸è¼ƒæ–¼èˆŠç‰ˆ Chat Completions APIï¼š

```python
# âŒ èˆŠç‰ˆ Chat Completions API
response = client.chat.completions.create(
    model="gpt-4",
    messages=[...]
)
reply = response.choices[0].message.content

# âœ… æ–°ç‰ˆ Response API
response = client.responses.create(
    model="gpt-5",
    input=[...],
    reasoning={"effort": "medium"},
    text={"verbosity": "medium"}
)
reply = response.output_text
```

**ä¸»è¦å„ªå‹¢**ï¼š
- æ”¯æ´æ¨ç†ç­‰ç´šæ§åˆ¶ï¼ˆ`reasoning`ï¼‰
- æ”¯æ´è¼¸å‡ºè©³ç´°åº¦æ§åˆ¶ï¼ˆ`text.verbosity`ï¼‰
- æ›´å¥½çš„å°è©±æ­·å²ç®¡ç†ï¼ˆä½¿ç”¨ `previous_response_id`ï¼‰
- å°ˆç‚º GPT-5 ç­‰æ¨ç†æ¨¡å‹å„ªåŒ–

### Gradio ç‹€æ…‹ç®¡ç†

é€™å€‹å¯¦ä½œä½¿ç”¨äº†æ”¹é€²çš„ç‹€æ…‹ç®¡ç†ç­–ç•¥ï¼š

**å…¨åŸŸç‹€æ…‹è®Šæ•¸**ï¼š
- `conversation_history`ï¼šå„²å­˜å°è©±æ­·å²ï¼ˆåŒ…å« user å’Œ assistant è¨Šæ¯ï¼‰
- `last_response_id`ï¼šResponse API çš„ previous_response_id
- `pdf_state`ï¼šPDF ç‹€æ…‹ï¼ˆä½¿ç”¨ dataclass çµæ§‹åŒ–ç®¡ç†ï¼‰

**é—œéµæ”¹é€²**ï¼š
1. **æ­£ç¢ºå„²å­˜å°è©±**ï¼šæ¯æ¬¡å°è©±å¾Œï¼ŒåŒæ™‚å„²å­˜ user å’Œ assistant è¨Šæ¯
2. **PDF ç‰ˆæœ¬è¿½è¹¤**ï¼šä½¿ç”¨ç‰ˆæœ¬è™Ÿå€åˆ†ä¸åŒçš„ PDF
3. **ç‹€æ…‹ç¨ç«‹æ€§**ï¼šæ¸…é™¤å°è©±ä¸æœƒå½±éŸ¿ PDF è¨­å®š

### æ•™å­¸æ³•æ•´åˆ

**è²»æ›¼å­¸ç¿’æ³•**ï¼š
- å¼·åˆ¶æ¨¡å‹ç”¨ç°¡å–®èªè¨€è§£é‡‹
- è¦æ±‚ä½¿ç”¨é¡æ¯”å’Œä¾‹å­
- é¿å…ç›´æ¥ä½¿ç”¨å°ˆæ¥­è¡“èª

**è˜‡æ ¼æ‹‰åº•å¼æå•**ï¼š
- ä¸ç›´æ¥çµ¦ç­”æ¡ˆ
- å¼•å°å­¸ç”Ÿæ€è€ƒ
- æå‡ºå•Ÿç™¼æ€§å•é¡Œ

---

## ğŸ› å¸¸è¦‹éŒ¯èª¤èˆ‡ä¿®æ­£

### éŒ¯èª¤ 1: å°è©±æ­·å²éºå¤±

**åŸæœ¬çš„å•é¡Œ**ï¼š
```python
# âŒ åªå„²å­˜ assistant çš„å›æ‡‰
conversation_history.extend(response.output)
```

**ä¿®æ­£å¾Œ**ï¼š
```python
# âœ… åŒæ™‚å„²å­˜ user å’Œ assistant è¨Šæ¯
conversation_history.append({"role": "user", "content": user_message})
conversation_history.append({"role": "assistant", "content": assistant_reply})
```

### éŒ¯èª¤ 2: PDF é‡æ–°ä¸Šå‚³ç„¡æ•ˆ

**åŸæœ¬çš„å•é¡Œ**ï¼š
åªåœ¨ç¬¬ä¸€æ¬¡æå•æ™‚æ³¨å…¥ PDF å…§å®¹ï¼Œå¾ŒçºŒä¸Šå‚³æ–° PDF æ™‚æ¨¡å‹ä¸çŸ¥é“ã€‚

**ä¿®æ­£å¾Œ**ï¼š
```python
# âœ… æ¯æ¬¡å‘¼å«éƒ½é‡æ–°æ³¨å…¥ PDF å…§å®¹
pdf_context = pdf_state.context_message()
if pdf_context:
    messages.append(pdf_context)
```

### éŒ¯èª¤ 3: Response API ç‹€æ…‹èª¤ç”¨

**åŸæœ¬çš„å•é¡Œ**ï¼š
```python
# âŒ ç›´æ¥æŠŠ response.output æ”¾å› input
conversation_history.extend(response.output)
```

**ä¿®æ­£å¾Œ**ï¼š
```python
# âœ… æ­£ç¢ºä½¿ç”¨ previous_response_id
last_response_id = getattr(response, "id", None)
if last_response_id:
    request_payload["previous_response_id"] = last_response_id
```

### éŒ¯èª¤ 4: æœªè™•ç†é‚Šç•Œæƒ…æ³

**ä¿®æ­£**ï¼š
- è™•ç† `history=None`ï¼šä½¿ç”¨ `ensure_history()` å‡½æ•¸
- è™•ç†ç©ºç™½è¼¸å‡ºï¼šä½¿ç”¨ `summarise_outputs()` å‡½æ•¸ä¸¦æä¾›é è¨­è¨Šæ¯
- è™•ç† PDF æå–å¤±æ•—ï¼šä½¿ç”¨ try-except ä¸¦é‡ç½®ç‹€æ…‹

---

## ğŸš€ å¯èƒ½çš„æ”¹é€²æ–¹å‘

1. **PDF åˆ†æ®µè™•ç†**ï¼šå°æ–¼è¶…é•·è«–æ–‡ï¼Œå¯ä»¥å…ˆåˆ†æçµæ§‹ï¼Œè®“ä½¿ç”¨è€…é¸æ“‡è¦è®€å“ªä¸€æ®µ
2. **è¦–è¦ºåŒ–**ï¼šç”¢ç”Ÿè«–æ–‡çµæ§‹åœ–ã€æ¦‚å¿µé—œä¿‚åœ–
3. **ç­†è¨˜åŠŸèƒ½**ï¼šè®“ä½¿ç”¨è€…å„²å­˜é‡è¦çš„å•ç­”
4. **å¤šè«–æ–‡æ¯”è¼ƒ**ï¼šä¸Šå‚³å¤šç¯‡è«–æ–‡ï¼Œæ¯”è¼ƒç•°åŒ
5. **åŒ¯å‡ºåŠŸèƒ½**ï¼šå°‡å°è©±åŒ¯å‡ºç‚ºç­†è¨˜æ–‡ä»¶

---

## ğŸ“ ä½œæ¥­èªªæ˜

### è¨­è¨ˆç†å¿µ

é€™å€‹è«–æ–‡é–±è®€åŠ©æ‰‹çš„æ ¸å¿ƒåƒ¹å€¼åœ¨æ–¼ï¼š

1. **ä¸åªæ˜¯æ‘˜è¦å·¥å…·**ï¼šä¸æ˜¯ç°¡å–®çš„ TL;DRï¼Œè€Œæ˜¯äº’å‹•å¼å­¸ç¿’åŠ©æ‰‹
2. **æ•™å­¸å°å‘**ï¼šæ•´åˆè²»æ›¼å­¸ç¿’æ³•å’Œè˜‡æ ¼æ‹‰åº•å¼æå•æ³•
3. **æŠ€è¡“å±•ç¤º**ï¼šä½¿ç”¨æœ€æ–°çš„ Response APIï¼Œå±•ç¤ºå°æ–°æŠ€è¡“çš„æŒæ¡
4. **å¯¦ç”¨æ€§**ï¼šçœŸæ­£èƒ½å¹«åŠ©å­¸ç”Ÿç†è§£è«–æ–‡

### èˆ‡è€å¸«ç¯„ä¾‹çš„å·®ç•°

è€å¸«çš„ã€Œå“¡ç‘›å¼æ€è€ƒç”Ÿæˆå™¨ã€ï¼š
- å–®ä¸€åŠŸèƒ½ï¼šæƒ…ç·’è½‰æ›
- ç°¡å–®è¼¸å…¥è¼¸å‡º
- å›ºå®šæ¨¡å¼

æˆ‘çš„ã€Œè«–æ–‡é–±è®€åŠ©æ‰‹ã€ï¼š
- å¤šåŠŸèƒ½ï¼šPDF è™•ç† + å¤šè¼ªå°è©±
- è¤‡é›œäº’å‹•ï¼šä¸Šå‚³ã€æå•ã€æ¸…é™¤
- æ•™å­¸æ³•æ•´åˆï¼šè²»æ›¼ + è˜‡æ ¼æ‹‰åº•
- æŠ€è¡“å‡ç´šï¼šResponse API

**è©•åˆ†å„ªå‹¢**ï¼š
- âœ… é¿é–‹ 6 åˆ†é™·é˜±ï¼ˆä¸åªæ˜¯æ”¹è®Šäººè¨­ï¼‰
- âœ… å¯¦ç”¨åƒ¹å€¼é«˜ï¼ˆçœŸçš„èƒ½ç”¨ä¾†è®€è«–æ–‡ï¼‰
- âœ… æŠ€è¡“å±•ç¤ºï¼ˆResponse API + PDF è™•ç†ï¼‰
- âœ… æ•™è‚²æ„ç¾©ï¼ˆæ•´åˆå­¸ç¿’ç†è«–ï¼‰

---

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

**Q: PDF ä¸Šå‚³å¤±æ•—ï¼Ÿ**
- ç¢ºèªæª”æ¡ˆæ˜¯ PDF æ ¼å¼
- æª¢æŸ¥æª”æ¡ˆæ˜¯å¦æå£
- å˜—è©¦ç”¨å…¶ä»– PDF é–±è®€å™¨é–‹å•Ÿç¢ºèª

**Q: API éŒ¯èª¤ï¼Ÿ**
- ç¢ºèª Colab Secrets ä¸­æœ‰è¨­å®š `OpenAI` é‡‘é‘°
- æª¢æŸ¥é‡‘é‘°æ˜¯å¦æœ‰æ•ˆä¸”æœ‰é¤˜é¡
- æŸ¥çœ‹éŒ¯èª¤è¨Šæ¯ä¸­çš„å…·é«”åŸå› 

**Q: å›æ‡‰å¤ªæ…¢ï¼Ÿ**
- é™ä½ `reasoning.effort` ç‚º `"low"` æˆ– `"minimal"`
- é™ä½ `text.verbosity` ç‚º `"low"`
- è€ƒæ…®ä½¿ç”¨ `gpt-5-mini` æˆ– `gpt-5-nano`

**Q: Token è¶…éé™åˆ¶ï¼Ÿ**
- PDF å¤ªé•·ï¼ˆè¶…é 100 é å»ºè­°åˆ†æ®µè™•ç†ï¼‰
- å°è©±æ­·å²å¤ªé•·ï¼ˆé»æ“Šæ¸…é™¤å°è©±é‡æ–°é–‹å§‹ï¼‰

**Q: å°è©±æ­·å²æ€éº¼éƒ½ä¸è¦‹äº†ï¼Ÿ**
- æª¢æŸ¥æ˜¯å¦æ­£ç¢ºå„²å­˜ user å’Œ assistant è¨Šæ¯
- ç¢ºèªæ²’æœ‰æ„å¤–é‡ç½® `conversation_history`

**Q: é‡æ–°ä¸Šå‚³ PDF å¾Œæ¨¡å‹é‚„åœ¨å›ç­”èˆŠçš„å…§å®¹ï¼Ÿ**
- ç¢ºèªæ¯æ¬¡å‘¼å«éƒ½æœ‰é‡æ–°æ³¨å…¥ PDF å…§å®¹
- æª¢æŸ¥ PDF ç‰ˆæœ¬è™Ÿæ˜¯å¦æœ‰éå¢

---

## ğŸ“š åƒè€ƒè³‡æº

- [OpenAI Response API æ–‡ä»¶](https://platform.openai.com/docs/api-reference/responses)
- [Gradio æ–‡ä»¶](https://www.gradio.app/docs)
- [PyPDF2 æ–‡ä»¶](https://pypdf2.readthedocs.io/)
- [è²»æ›¼å­¸ç¿’æ³•](https://en.wikipedia.org/wiki/Feynman_Technique)
- [è˜‡æ ¼æ‹‰åº•å¼æå•æ³•](https://en.wikipedia.org/wiki/Socratic_method)

---

## ğŸ™ è‡´è¬

é€™å€‹å¯¦ä½œçš„æ”¹é€²å¾—ç›Šæ–¼ï¼š
- **Codex AI** çš„ç¨‹å¼ç¢¼å¯©æŸ¥èˆ‡éŒ¯èª¤ä¿®æ­£
- **Claude Code** çš„å‹å–„æ–‡æª”èˆ‡æ•™å­¸è¨­è¨ˆ

å…©è€…çµåˆç”¢ç”Ÿäº†é€™å€‹æ—¢ç©©å¥åˆæ˜“è®€çš„å¯¦ä½œã€‚

---

*ğŸ¤– Generated with Claude Code + OpenAI GPT-5 Response API*
