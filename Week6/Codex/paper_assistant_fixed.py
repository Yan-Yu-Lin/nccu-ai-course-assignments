#!/usr/bin/env python3
"""Corrected Paper Reading Assistant using the OpenAI Responses API."""

from __future__ import annotations

import os
from dataclasses import dataclass
from typing import List, Dict, Optional, Any

import gradio as gr
import PyPDF2

try:
    from google.colab import userdata  # type: ignore
except ImportError:  # pragma: no cover - fallback for local runs
    userdata = None

from openai import OpenAI


# --- OpenAI client bootstrap -------------------------------------------------

def _resolve_api_key() -> Optional[str]:
    if userdata is not None:
        key = userdata.get("OpenAI")
        if key:
            return key
    return os.getenv("OPENAI_API_KEY")


api_key = _resolve_api_key()
if api_key:
    os.environ["OPENAI_API_KEY"] = api_key

client = OpenAI()
MODEL_NAME = "gpt-5"


# --- Prompt scaffolding ------------------------------------------------------

SYSTEM_PROMPT = (
    "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è«–æ–‡é–±è®€åŠ©æ‰‹ã€‚é‹ç”¨è²»æ›¼å­¸ç¿’æ³•èˆ‡è˜‡æ ¼æ‹‰åº•å¼æå•æ³•ï¼Œç”¨æ¸…æ¥šã€å‹å–„çš„èªæ°£"
    "å”åŠ©å­¸ç”Ÿç†è§£è«–æ–‡å…§å®¹èˆ‡ç ”ç©¶æ–¹æ³•ï¼›å¦‚æœå•é¡Œèˆ‡ä¸Šå‚³çš„è«–æ–‡ç„¡é—œï¼Œä¹Ÿè¦ä»¥ä¸€èˆ¬ AI åŠ©æ‰‹çš„èº«ä»½çµ¦äºˆ"
    "å®Œæ•´ã€å¯¦ç”¨çš„è§£ç­”ã€‚"
)

PDF_CONTEXT_TEMPLATE = (
    "ä»¥ä¸‹æ˜¯ä½¿ç”¨è€…æä¾›çš„è«–æ–‡å…§å®¹ (æª”å: {filename}, ç‰ˆæœ¬: {version})ï¼Œå›ç­”æ™‚å‹™å¿…å¼•ç”¨æ­¤å…§å®¹ï¼š\n"
    "{content}"
)

MAX_PDF_CHARS = 15000  # é˜²æ­¢è¶…é‡ tokenï¼Œæé†’ä½¿ç”¨è€…åˆ†æ®µæå•


# --- Stateful containers -----------------------------------------------------

@dataclass
class PDFState:
    filename: Optional[str] = None
    content: Optional[str] = None
    version: int = 0

    def context_message(self) -> Optional[Dict[str, str]]:
        if not self.content or not self.filename:
            return None
        return {
            "role": "user",
            "content": PDF_CONTEXT_TEMPLATE.format(
                filename=self.filename,
                version=self.version,
                content=self.content,
            ),
        }


conversation_history: List[Dict[str, str]] = []
last_response_id: Optional[str] = None
pdf_state = PDFState()


# --- Helpers -----------------------------------------------------------------

def extract_pdf_text(pdf_path: str) -> str:
    if not pdf_path:
        raise ValueError("æœªæä¾› PDF æª”æ¡ˆ")

    text_segments: List[str] = []
    try:
        with open(pdf_path, "rb") as handle:
            pdf_reader = PyPDF2.PdfReader(handle)
            if not pdf_reader.pages:
                raise ValueError("PDF ä¸­æ²’æœ‰å¯ç”¨é é¢")

            for index, page in enumerate(pdf_reader.pages, start=1):
                page_text = page.extract_text() or ""
                if page_text.strip():
                    text_segments.append(f"\n--- Page {index} ---\n{page_text.strip()}")

    except Exception as exc:  # PyPDF2 raises many custom exceptions
        raise ValueError(f"PDF è®€å–å¤±æ•—: {exc}") from exc

    if not text_segments:
        raise ValueError("PDF ä¸­æ²’æœ‰å¯è®€å–çš„æ–‡å­—å…§å®¹")

    combined = "".join(text_segments)
    if len(combined) > MAX_PDF_CHARS:
        combined = combined[:MAX_PDF_CHARS] + "\n\n... (å…§å®¹éé•·ï¼Œå·²æˆªæ–·ã€‚è«‹åˆ†æ®µæå•ä»¥ç²å¾—å®Œæ•´è§£èªªã€‚)"
    return combined


def summarise_outputs(response: Any) -> str:
    if getattr(response, "output_text", None):
        return response.output_text

    collected: List[str] = []
    for item in getattr(response, "output", []) or []:
        if item.get("type") != "message":
            continue
        for chunk in item.get("content", []):
            if chunk.get("type") == "output_text" and chunk.get("text"):
                collected.append(chunk["text"])

    return "".join(collected).strip()


def ensure_history(history: Optional[List[List[str]]]) -> List[List[str]]:
    return list(history) if history else []


# --- Core chat logic ---------------------------------------------------------

def chat_with_paper(message: str, history: Optional[List[List[str]]]):
    global conversation_history, last_response_id

    history = ensure_history(history)
    user_message = (message or "").strip()
    if not user_message:
        return history

    messages: List[Dict[str, str]] = [{"role": "developer", "content": SYSTEM_PROMPT}]

    pdf_context = pdf_state.context_message()
    if pdf_context:
        messages.append(pdf_context)

    messages.extend(conversation_history)
    messages.append({"role": "user", "content": user_message})

    request_payload = {
        "model": MODEL_NAME,
        "input": messages,
        "reasoning": {"effort": "medium"},
        "text": {"verbosity": "medium"},
    }
    if last_response_id:
        request_payload["previous_response_id"] = last_response_id

    try:
        response = client.responses.create(**request_payload)
        assistant_reply = summarise_outputs(response)
        if not assistant_reply:
            assistant_reply = "âš ï¸ æ¨¡å‹æœªå›å‚³æ–‡å­—ï¼Œå¯å†è©¦ä¸€æ¬¡æˆ–èª¿æ•´å•é¡Œã€‚"

        conversation_history.append({"role": "user", "content": user_message})
        conversation_history.append({"role": "assistant", "content": assistant_reply})
        last_response_id = getattr(response, "id", None)

        history.append([user_message, assistant_reply])
        return history

    except Exception as exc:
        error_message = f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{exc}\n\nè«‹æª¢æŸ¥ç¶²è·¯é€£ç·šèˆ‡ API è¨­å®šå¾Œå†è©¦ä¸€æ¬¡ã€‚"
        history.append([user_message, error_message])
        return history


def upload_pdf(pdf_file: Optional[str]):
    global pdf_state

    if pdf_file is None:
        return "âŒ è«‹é¸æ“‡ PDF æª”æ¡ˆ"

    try:
        content = extract_pdf_text(pdf_file)
    except ValueError as exc:
        pdf_state = PDFState()  # ä¿æŒç‹€æ…‹ä¸€è‡´
        return f"âŒ {exc}"

    pdf_state = PDFState(
        filename=os.path.basename(pdf_file),
        content=content,
        version=pdf_state.version + 1,
    )

    page_count = content.count("--- Page") or "?"
    char_count = len(content)

    note = (
        "âœ… PDF ä¸Šå‚³æˆåŠŸï¼\n\n"
        f"ğŸ“„ æª”åï¼š{pdf_state.filename}\n"
        f"ğŸ“„ ç‰ˆæœ¬ï¼š{pdf_state.version}\n"
        f"ğŸ“„ é é¢æ•¸ï¼šç´„ {page_count}\n"
        f"ğŸ”¤ æ–‡å­—é•·åº¦ï¼šç´„ {char_count:,} å­—å…ƒ\n\n"
        "ğŸ’¬ ä½ å¯ä»¥ç›´æ¥æå•ï¼Œæˆ‘æœƒä¾æ“šæœ€æ–°çš„ PDF å›ç­”ã€‚"
    )
    return note


def clear_conversation():
    global conversation_history, last_response_id
    conversation_history = []
    last_response_id = None
    return [], "ğŸ”„ å°è©±å·²æ¸…é™¤ï¼PDF è¨­å®šä¿æŒä¸è®Šã€‚"


# --- Gradio UI ---------------------------------------------------------------

WELCOME_MESSAGE = (
    "ğŸ‘‹ å—¨ï¼æˆ‘æ˜¯ä½ çš„è«–æ–‡é–±è®€åŠ©æ‰‹ã€‚\n\n"
    "ğŸ“„ ä¸Šå‚³ PDF å¾Œï¼Œæˆ‘æœƒæ ¹æ“šå…§å®¹ç”¨ç°¡å–®èªè¨€è¬›è§£ï¼›è‹¥æ²’æœ‰ PDFï¼Œä¹Ÿå¯ä»¥ç›´æ¥èˆ‡æˆ‘èŠå¤©ã€‚\n"
    "ğŸ’¡ ä½ å¯ä»¥éš¨æ™‚é‡æ–°ä¸Šå‚³æ–°çš„ PDFï¼Œå°è©±æ­·å²æœƒä¿ç•™ã€‚"
)


with gr.Blocks(title="è«–æ–‡é–±è®€åŠ©æ‰‹ (Fixed)", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ“š è«–æ–‡é–±è®€åŠ©æ‰‹ - Paper Reading Assistant (Fixed Edition)")
    gr.Markdown("ä½¿ç”¨ OpenAI Responses APIï¼Œæ”¯æ´ PDF èˆ‡ä¸€èˆ¬å°è©±é›™æ¨¡å¼ã€‚")

    with gr.Row():
        with gr.Column(scale=3):
            pdf_upload = gr.File(
                label="ğŸ“„ ä¸Šå‚³è«–æ–‡ PDF",
                file_types=[".pdf"],
                type="filepath",
            )
            upload_status = gr.Textbox(
                label="ä¸Šå‚³ç‹€æ…‹",
                value=WELCOME_MESSAGE,
                interactive=False,
                lines=10,
            )

        with gr.Column(scale=7):
            chatbot = gr.Chatbot(
                label="ğŸ’¬ å°è©±å€",
                height=500,
                type="tuples",
            )
            msg_input = gr.Textbox(
                label="è¼¸å…¥ä½ çš„å•é¡Œ",
                placeholder="ä¾‹å¦‚ï¼šé€™ç¯‡è«–æ–‡çš„ä¸»è¦è²¢ç»æ˜¯ä»€éº¼ï¼Ÿ",
                lines=2,
            )

            with gr.Row():
                submit_btn = gr.Button("ğŸ“¤ é€å‡º", variant="primary")
                clear_btn = gr.Button("ğŸ”„ æ¸…é™¤å°è©±")

    pdf_upload.change(upload_pdf, inputs=pdf_upload, outputs=upload_status)

    submit_btn.click(
        fn=chat_with_paper,
        inputs=[msg_input, chatbot],
        outputs=chatbot,
    ).then(lambda: "", outputs=msg_input)

    msg_input.submit(
        fn=chat_with_paper,
        inputs=[msg_input, chatbot],
        outputs=chatbot,
    ).then(lambda: "", outputs=msg_input)

    clear_btn.click(fn=clear_conversation, outputs=[chatbot, upload_status])

    gr.Markdown(
        """
---
### ä½¿ç”¨å»ºè­°

- é¦–æ¬¡æå•å¯å…ˆè«‹æˆ‘ç”¨ä¸€å¥è©±æ¦‚è¿°è«–æ–‡ã€‚
- å¦‚æœæ–‡å­—éé•·è¢«æˆªæ–·ï¼Œè«‹å˜—è©¦åˆ†ç« ç¯€æå•ã€‚
- é‡æ–°ä¸Šå‚³ PDF å¾Œï¼Œç›´æ¥æå•å³å¯ï¼Œæˆ‘æœƒåƒè€ƒæœ€æ–°ç‰ˆæœ¬ã€‚
        """
    )


if __name__ == "__main__":
    demo.launch(share=True, debug=True)
