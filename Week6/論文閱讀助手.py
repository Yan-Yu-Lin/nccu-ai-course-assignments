#!/usr/bin/env python3
"""
Python script generated from: Week6/è«–æ–‡é–±è®€åŠ©æ‰‹.md
Generated on: 1760865755.1443665
Note: Colab-specific commands (!pip, %magic) have been commented out
"""

# COLAB ONLY: !pip install openai gradio pypdf2

from google.colab import userdata
import os

api_key = userdata.get('OpenAI')
os.environ['OPENAI_API_KEY'] = api_key

from openai import OpenAI
import gradio as gr
import PyPDF2
import io

client = OpenAI()
model = "gpt-5"

def extract_pdf_text(pdf_file):
    """
    å¾ä¸Šå‚³çš„ PDF æª”æ¡ˆä¸­æå–æ–‡å­—å…§å®¹

    Args:
        pdf_file: Gradio ä¸Šå‚³çš„æª”æ¡ˆç‰©ä»¶

    Returns:
        str: æå–çš„æ–‡å­—å…§å®¹
    """
    if pdf_file is None:
        return None

    try:
        # è®€å– PDF æª”æ¡ˆ
        pdf_reader = PyPDF2.PdfReader(pdf_file)

        # æå–æ‰€æœ‰é é¢çš„æ–‡å­—
        text = ""
        for page_num, page in enumerate(pdf_reader.pages):
            page_text = page.extract_text()
            text += f"\n--- Page {page_num + 1} ---\n{page_text}\n"

        return text

    except Exception as e:
        return f"âŒ PDF è®€å–å¤±æ•—ï¼š{str(e)}"

SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è«–æ–‡é–±è®€åŠ©æ‰‹ï¼Œå°ˆé–€å¹«åŠ©å­¸ç”Ÿç†è§£å­¸è¡“è«–æ–‡ã€‚

**ä½ çš„æ•™å­¸åŸå‰‡**ï¼š

1. **è²»æ›¼å­¸ç¿’æ³• (Feynman Technique)**ï¼š
   - ç”¨æœ€ç°¡å–®çš„èªè¨€è§£é‡‹è¤‡é›œæ¦‚å¿µ
   - ä½¿ç”¨é¡æ¯”å’Œæ—¥å¸¸ç”Ÿæ´»çš„ä¾‹å­
   - é¿å…éåº¦ä½¿ç”¨å°ˆæ¥­è¡“èªï¼Œå¿…è¦æ™‚è¦å…ˆè§£é‡‹

2. **è˜‡æ ¼æ‹‰åº•å¼æå• (Socratic Method)**ï¼š
   - ä¸ç›´æ¥çµ¦ç­”æ¡ˆï¼Œè€Œæ˜¯å¼•å°å­¸ç”Ÿæ€è€ƒ
   - æå‡ºå•Ÿç™¼æ€§å•é¡Œï¼Œå¹«åŠ©å­¸ç”Ÿè‡ªå·±æ‰¾åˆ°ç­”æ¡ˆ
   - é¼“å‹µæ‰¹åˆ¤æ€§æ€ç¶­

3. **çµæ§‹åŒ–åˆ†æ**ï¼š
   - å¹«åŠ©å­¸ç”Ÿç†è§£è«–æ–‡çµæ§‹ï¼šæ‘˜è¦ã€å¼•è¨€ã€æ–¹æ³•ã€çµæœã€çµè«–
   - æŒ‡å‡ºè«–æ–‡çš„æ ¸å¿ƒè²¢ç»å’Œå‰µæ–°é»
   - è§£é‡‹ç ”ç©¶æ–¹æ³•å’Œå¯¦é©—è¨­è¨ˆ

4. **å‹å–„äº’å‹•**ï¼š
   - ä»¥é¼“å‹µå’Œæ”¯æŒçš„èªæ°£å›æ‡‰
   - ç¢ºèªå­¸ç”Ÿç†è§£å¾Œå†ç¹¼çºŒ
   - å¯ä»¥ç”¨ emoji è®“å°è©±æ›´ç”Ÿå‹•

**ç•¶å­¸ç”Ÿä¸Šå‚³è«–æ–‡å¾Œ**ï¼š
- ç­‰å¾…å­¸ç”Ÿæå•ï¼Œä¸è¦ä¸»å‹•æ‘˜è¦
- æ ¹æ“šå­¸ç”Ÿçš„å•é¡Œï¼Œå¾è«–æ–‡ä¸­æ‰¾åˆ°ç›¸é—œå…§å®¹å›ç­”
- ç¢ºä¿å›ç­”æº–ç¢ºä¸”åŸºæ–¼è«–æ–‡å…§å®¹

**è¨˜ä½**ï¼šä½ çš„ç›®æ¨™æ˜¯å¹«åŠ©å­¸ç”Ÿã€Œå­¸æœƒå¦‚ä½•è®€è«–æ–‡ã€ï¼Œè€Œä¸åªæ˜¯ã€Œè®€æ‡‚é€™ç¯‡è«–æ–‡ã€ã€‚"""

WELCOME_MESSAGE = """ğŸ‘‹ å—¨ï¼æˆ‘æ˜¯ä½ çš„**è«–æ–‡é–±è®€åŠ©æ‰‹ & AI å°è©±å¤¥ä¼´**ï¼

ğŸ“š **æˆ‘èƒ½å¹«ä½ åšä»€éº¼ï¼Ÿ**

**æ¨¡å¼ 1ï¼šè«–æ–‡é–±è®€åŠ©æ‰‹** ğŸ“„
- ä¸Šå‚³ PDF è«–æ–‡å¾Œï¼Œæˆ‘æœƒå¹«ä½ ï¼š
  - ç”¨ç°¡å–®çš„èªè¨€è§£é‡‹è«–æ–‡ä¸­çš„è¤‡é›œæ¦‚å¿µ
  - å¹«ä½ ç†è§£ç ”ç©¶æ–¹æ³•å’Œå¯¦é©—è¨­è¨ˆ
  - å¼•å°ä½ æ€è€ƒè«–æ–‡çš„æ ¸å¿ƒè²¢ç»
  - å›ç­”ä½ å°è«–æ–‡å…§å®¹çš„ä»»ä½•ç–‘å•

**æ¨¡å¼ 2ï¼šä¸€èˆ¬ AI åŠ©æ‰‹** ğŸ’¬
- ä¸ä¸Šå‚³ PDF ä¹Ÿå¯ä»¥ç›´æ¥è·Ÿæˆ‘èŠå¤©ï¼š
  - å­¸ç¿’ä»»ä½•ä¸»é¡Œ
  - è§£ç­”å•é¡Œ
  - è¨è«–æƒ³æ³•
  - å¯«ä½œå”åŠ©

ğŸš€ **å¦‚ä½•é–‹å§‹ï¼Ÿ**
- **æƒ³è®€è«–æ–‡ï¼Ÿ** é»æ“Šä¸Šæ–¹ã€Œä¸Šå‚³ PDFã€æŒ‰éˆ•
- **æƒ³èŠå¤©ï¼Ÿ** ç›´æ¥é–‹å§‹æå•å³å¯ï¼

ğŸ’¡ **æå•ç¯„ä¾‹**ï¼š
- ğŸ“– è«–æ–‡ç›¸é—œï¼šã€Œé€™ç¯‡è«–æ–‡çš„ä¸»è¦è²¢ç»æ˜¯ä»€éº¼ï¼Ÿã€
- ğŸ’¬ ä¸€èˆ¬å°è©±ï¼šã€Œè§£é‡‹ä¸€ä¸‹æ©Ÿå™¨å­¸ç¿’çš„åŸºæœ¬æ¦‚å¿µã€

æº–å‚™å¥½äº†å—ï¼Ÿé–‹å§‹ä½ çš„æ¢ç´¢ä¹‹æ—…å§ï¼ ğŸš€âœ¨"""

# å…¨åŸŸç‹€æ…‹
pdf_content = None
conversation_history = []

def chat_with_paper(message, history):
    """
    è™•ç†ä½¿ç”¨è€…è¨Šæ¯ä¸¦ç”¢ç”Ÿå›æ‡‰

    æ”¯æ´å…©ç¨®æ¨¡å¼ï¼š
    1. æœ‰ PDFï¼šè«–æ–‡é–±è®€åŠ©æ‰‹æ¨¡å¼
    2. ç„¡ PDFï¼šä¸€èˆ¬ AI åŠ©æ‰‹æ¨¡å¼

    Args:
        message: ä½¿ç”¨è€…ç•¶å‰è¼¸å…¥
        history: Gradio èŠå¤©æ­·å² [[user_msg, bot_msg], ...]

    Returns:
        list: æ›´æ–°å¾Œçš„ Gradio æ­·å²è¨˜éŒ„ï¼ˆå¿…é ˆæ˜¯ list of lists æ ¼å¼ï¼‰
    """
    global pdf_content, conversation_history

    try:
        # å»ºæ§‹è¨Šæ¯åˆ—è¡¨
        messages = [
            {"role": "developer", "content": SYSTEM_PROMPT}
        ]

        # === æƒ…æ³ 1ï¼šæœ‰ PDFï¼Œè«–æ–‡é–±è®€æ¨¡å¼ ===
        if pdf_content is not None and not pdf_content.startswith("âŒ"):
            # ç¬¬ä¸€æ¬¡æå•æ™‚ï¼ŒåŒ…å« PDF å…§å®¹
            if len(conversation_history) == 0:
                messages.append({
                    "role": "user",
                    "content": f"ä»¥ä¸‹æ˜¯æˆ‘è¦é–±è®€çš„è«–æ–‡å…§å®¹ï¼š\n\n{pdf_content}\n\n---\n\nç¾åœ¨æˆ‘çš„å•é¡Œæ˜¯ï¼š{message}"
                })
            else:
                # å¾ŒçºŒå°è©±ï¼ŒåŠ å…¥æ­·å²è¨Šæ¯
                messages.extend(conversation_history)
                messages.append({
                    "role": "user",
                    "content": message
                })

        # === æƒ…æ³ 2ï¼šç„¡ PDF æˆ– PDF è®€å–å¤±æ•—ï¼Œä¸€èˆ¬èŠå¤©æ¨¡å¼ ===
        else:
            # åŠ å…¥å°è©±æ­·å²ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
            if len(conversation_history) > 0:
                messages.extend(conversation_history)

            # åŠ å…¥ç•¶å‰ä½¿ç”¨è€…è¨Šæ¯
            messages.append({
                "role": "user",
                "content": message
            })

        # å‘¼å« OpenAI Response API
        response = client.responses.create(
            model=model,
            input=messages,
            reasoning={"effort": "medium"},
            text={"verbosity": "medium"}
        )

        # å–å¾—å›æ‡‰
        reply = response.output_text

        # æ›´æ–°å°è©±æ­·å²ï¼ˆåŒ…å«å®Œæ•´çš„ outputï¼‰
        conversation_history.extend(response.output)

        # æ›´æ–° Gradio é¡¯ç¤ºçš„æ­·å²ï¼ˆé‡è¦ï¼å¿…é ˆå›å‚³ Gradio æ ¼å¼ï¼‰
        return history + [[message, reply]]

    except Exception as e:
        # éŒ¯èª¤è™•ç†ï¼šåŒæ¨£å›å‚³ Gradio æ ¼å¼
        error_msg = f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}\n\nè«‹æª¢æŸ¥æ‚¨çš„ API Key æ˜¯å¦æ­£ç¢ºè¨­å®šã€‚"
        return history + [[message, error_msg]]


def upload_pdf(pdf_file):
    """
    è™•ç† PDF ä¸Šå‚³

    Args:
        pdf_file: Gradio ä¸Šå‚³çš„æª”æ¡ˆ

    Returns:
        str: ä¸Šå‚³ç‹€æ…‹è¨Šæ¯
    """
    global pdf_content, conversation_history

    if pdf_file is None:
        return "âŒ è«‹é¸æ“‡ PDF æª”æ¡ˆ"

    # æå– PDF æ–‡å­—
    pdf_content = extract_pdf_text(pdf_file)

    # é‡ç½®å°è©±æ­·å²
    conversation_history = []

    if pdf_content and not pdf_content.startswith("âŒ"):
        # è¨ˆç®—å­—æ•¸
        char_count = len(pdf_content)
        page_count = pdf_content.count("--- Page")

        return f"âœ… PDF ä¸Šå‚³æˆåŠŸï¼\n\nğŸ“„ å…± {page_count} é ï¼Œç´„ {char_count:,} å­—å…ƒ\n\nğŸ’¬ ç¾åœ¨å¯ä»¥é–‹å§‹å‘æˆ‘æå•äº†ï¼"
    else:
        return pdf_content  # å›å‚³éŒ¯èª¤è¨Šæ¯


def clear_conversation():
    """
    æ¸…é™¤å°è©±æ­·å²ï¼Œé‡æ–°é–‹å§‹

    Returns:
        tuple: (æ¸…ç©ºçš„èŠå¤©æ­·å², ç‹€æ…‹è¨Šæ¯)
    """
    global conversation_history
    conversation_history = []

    return [], "ğŸ”„ å°è©±å·²æ¸…é™¤ï¼ä½ å¯ä»¥é‡æ–°æå•ï¼Œæˆ–ä¸Šå‚³æ–°çš„ PDFã€‚"

# å»ºç«‹ Gradio ä»‹é¢
with gr.Blocks(title="è«–æ–‡é–±è®€åŠ©æ‰‹", theme=gr.themes.Soft()) as demo:

    gr.Markdown("# ğŸ“š è«–æ–‡é–±è®€åŠ©æ‰‹ - Paper Reading Assistant")
    gr.Markdown("åŸºæ–¼ OpenAI GPT-5 Response APIï¼Œçµåˆè²»æ›¼å­¸ç¿’æ³•èˆ‡è˜‡æ ¼æ‹‰åº•å¼æå•")

    with gr.Row():
        with gr.Column(scale=3):
            # PDF ä¸Šå‚³å€
            pdf_upload = gr.File(
                label="ğŸ“„ ä¸Šå‚³è«–æ–‡ PDF",
                file_types=[".pdf"],
                type="filepath"
            )
            upload_status = gr.Textbox(
                label="ä¸Šå‚³ç‹€æ…‹",
                value=WELCOME_MESSAGE,
                interactive=False,
                lines=8
            )

        with gr.Column(scale=7):
            # èŠå¤©å€
            chatbot = gr.Chatbot(
                label="ğŸ’¬ å°è©±å€",
                height=500,
                show_label=True,
                type="tuples"  # æ˜ç¢ºæŒ‡å®šä½¿ç”¨ tuples æ ¼å¼
            )

            msg_input = gr.Textbox(
                label="è¼¸å…¥ä½ çš„å•é¡Œ",
                placeholder="ä¾‹å¦‚ï¼šé€™ç¯‡è«–æ–‡çš„ä¸»è¦è²¢ç»æ˜¯ä»€éº¼ï¼Ÿ",
                lines=2
            )

            with gr.Row():
                submit_btn = gr.Button("ğŸ“¤ é€å‡º", variant="primary")
                clear_btn = gr.Button("ğŸ”„ æ¸…é™¤å°è©±")

    # äº‹ä»¶ç¶å®š
    pdf_upload.change(
        fn=upload_pdf,
        inputs=pdf_upload,
        outputs=upload_status
    )

    submit_btn.click(
        fn=chat_with_paper,
        inputs=[msg_input, chatbot],
        outputs=chatbot
    ).then(
        lambda: "",  # æ¸…ç©ºè¼¸å…¥æ¡†
        outputs=msg_input
    )

    msg_input.submit(
        fn=chat_with_paper,
        inputs=[msg_input, chatbot],
        outputs=chatbot
    ).then(
        lambda: "",  # æ¸…ç©ºè¼¸å…¥æ¡†
        outputs=msg_input
    )

    clear_btn.click(
        fn=clear_conversation,
        outputs=[chatbot, upload_status]
    )

    # èªªæ˜å€
    gr.Markdown("""
    ---
    ### ğŸ’¡ ä½¿ç”¨æŠ€å·§

    - **ç¬¬ä¸€æ¬¡æå•**ï¼šå»ºè­°å…ˆå•ã€Œé€™ç¯‡è«–æ–‡åœ¨ç ”ç©¶ä»€éº¼ï¼Ÿã€äº†è§£å…¨è²Œ
    - **æ·±å…¥ç†è§£**ï¼šé‡å°ä¸æ‡‚çš„ç« ç¯€æˆ–æ¦‚å¿µæå•
    - **æ‰¹åˆ¤æ€è€ƒ**ï¼šå¯ä»¥å•ã€Œé€™å€‹æ–¹æ³•æœ‰ä»€éº¼é™åˆ¶ï¼Ÿã€
    - **æ¸…é™¤å°è©±**ï¼šæƒ³é‡æ–°é–‹å§‹æ™‚ï¼Œé»æ“Šã€Œæ¸…é™¤å°è©±ã€æŒ‰éˆ•

    ### âš™ï¸ æŠ€è¡“èªªæ˜

    - **æ¨¡å‹**ï¼šOpenAI GPT-5 (Response API)
    - **æ¨ç†ç­‰ç´š**ï¼šMedium (å¹³è¡¡é€Ÿåº¦èˆ‡å“è³ª)
    - **PDF è™•ç†**ï¼šPyPDF2 (å®Œæ•´æ–‡å­—æå–)
    - **ä»‹é¢æ¡†æ¶**ï¼šGradio 5.x

    ---
    *Made with â¤ï¸ for NCCU AI Course*
    """)

# å•Ÿå‹• Gradio æ‡‰ç”¨
demo.launch(share=True, debug=True)

# âŒ èˆŠç‰ˆ Chat Completions API
response = client.chat.completions.create(
    model="gpt-4",
    messages=[...]
)
reply = response.choices[0].message.content

# âœ… æ–°ç‰ˆ Response API
response = client.responses.create(
    model="gpt-5",
    input=[...],
    reasoning={"effort": "medium"},
    text={"verbosity": "medium"}
)
reply = response.output_text

